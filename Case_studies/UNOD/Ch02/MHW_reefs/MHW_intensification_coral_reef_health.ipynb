{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/tools/frameworks/-/raw/main/img/UN_decade_banner.png' align='right' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../../../../Index.ipynb\"><< Index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2024 EUMETSAT <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** Ben Loveday (EUMETSAT/Innoflair UG), Hayley Evers-King (EUMETSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <div style=\"width:100%\">\n",
    "    <div style=\"float:left\"><a href=\"https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2ocean-case-studies/HEAD?urlpath=%2Ftree%2FCase_studies%2FUN_Ocean_Decade%2FChallenge02_ecosystems_and_biodiversity%2FMarine_heat_wave_intensification_threatens_coral_reef_health%2FMarine_heat_wave_intensification_threatens_coral_reef_health.ipynb\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\"></a></div>\n",
    "    <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "  </div>\n",
    "  <div style=\"width:100%\">\n",
    "    <div style=\"float:left\"><a href=\"https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/UN_Ocean_Decade/Challenge02_ecosystems_and_biodiversity/Marine_heat_wave_intensification_threatens_coral_reef_health/Marine_heat_wave_intensification_threatens_coral_reef_health.ipynb\"><img src=\"https://img.shields.io/badge/launch-WEKEO-1a4696.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAMCAMAAACKnBfWAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAABwlBMVEUAYbdepNtBc7VCdLhNhMQkXKpsn9RWltFZl9VlpNI3aK9fpNtMd7ZznM8pg8o4WJc2TZFHY6MmQYptiLxnqt5hptxfpNtfpNtfpNtgpdtip9x2uullqN1fpNtdo9pepdtanNQ9a65Bc7dCeb5nqt5fpNslUpssW6RMgcBTjstWldJhptxdo9phoNdkpdtfpNtoqNxepNplo9hepNthnNNfpdtelM1hptxSgL5dj8hoqt5fpNsjRYgjPog8WqBHa61TfLplqN1fpdtfpdxam9IyTIw2TZFGYaBoqt5hptxfpdtepNpfpNtgpdtjp9x5vu5do9pHgb5co9pepNtHgbwWN4AVP5AhU6JLgL9dl89epNphpttgpdtipttnqd1ho9glSIkWM3snSokeTJdHda9cksphndRmqNyTweaWxOePv+WfyemAs91QYphFUmpuclhKYHRwh5V8pNNdls6iyuq72fCNvuWIueCIlbtTW2hwcFNTY2lmfpSBpNJZj8lsq91xr99nqdx4suBrqds7V5AlNm85S20lRIJVcZxZgr1Uh8NcotpbotpdpNtGfrcTKnAOKXsYOYo4XKRJcbNHfbf////t/CgnAAAAUHRSTlMAAAAAAAAAAAAAAAAAAAAAAAAAAByF2PfyxGAJLcH+9pQvJgsav/7s57hBf/3gQdO69vH18dK4fN0+GLz96uSzPCq99JArIgkagNTz7r9bB4DtcFsAAAABYktHRJUIYHqDAAAAB3RJTUUH5wIKESIRAg6dCwAAALtJREFUCNdjYGAUERUTl5CUkmZiZmFlY2CUkZULAAJ5BUUlZXYOBhXVADAIVFPX0NTiZNDWAXKCgkNCw8IjInX1GPSjomNi4+ITEpOSU1LTDBgM0zMys7JzcvPyCwqLio0YjKNKSstKyisqq6prautMGEwD6hsam5pbWtvaOzq7zBjMdbq7g3p6+/onTJw02cKSwcoaYt8UG1s7ewcuBm5HJ7B7nF1c3dx5eBn4uD08vbx9fP38+QUEhYQB5Z40RP8+e1wAAAAldEVYdGRhdGU6Y3JlYXRlADIwMjMtMDItMTBUMTc6MzM6NDUrMDA6MDCCLR1xAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIzLTAyLTEwVDE3OjI2OjU5KzAwOjAw393bowAAAABJRU5ErkJggg==\" alt=\"Open in WEkEO\"></a></div>\n",
    "    <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "  </div> \n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Ocean case studies</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "\n",
    "This notebook has the following prerequisites:\n",
    "- **<a href=\"https://my.wekeo.eu/user-registration\" target=\"_blank\">A WEkEO account</a>** to download from WEkEO\n",
    "    \n",
    "There are no prerequisite notebooks for this module, but you may wish to look at the following notebooks on using SLSTR data; <br>\n",
    "- **<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/sensors/learn-SLSTR\" target=\"_blank\">Learn SLSTR (EUMETSAT Gitlab)</a>**\n",
    "\n",
    "For more contextual information, users should refer to the following case study where the image we generate here is published:\n",
    "- **<a href=\"https://user.eumetsat.int/resources/case-studies/marine-heatwave-intensification-threatens-coral-reef-health\" target=\"_blank\">Marine heatwave intensification threatens coral reef health</a>**\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marine heatwave intensification threatens coral reef health\n",
    "<font color=\"#138D75\">**UN Ocean Decade Challenge 2: Protect and restore ecosystems and biodiversity**</font>\n",
    "\n",
    "### Data used\n",
    "\n",
    "| Dataset | EUMETSAT Data Store<br>collection ID | EUMETSAT collection<br>description | Copernicus Marine<br>Data Store product ID | Copernicus Marine<br>product description | WEkEO dataset ID | WEkEO dataset<br>description |\n",
    "|:--------------------:|:-----------------------:|:-----------------:|:-----------------:|:-----------------:|-----------------:|:-----------------:|\n",
    "| Sentinel-3 SLSTR level-2 | EO:EUM:DAT:0412 | <a href=\"https://navigator.eumetsat.int/product/EO:EUM:DAT:SENTINEL-3:SL_2_SST?query=SLSTR&s=advanced\" target=\"_blank\">Description</a> | - | - | EO:EUM:DAT:SENTINEL-3:SL_2_WST___ | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AEUM%3ADAT%3ASENTINEL-3%3ASL_2_WST___&initial=1\" target=\"_blank\">Description</a> |\n",
    "| Global OSTIA SST (Reprocessed) | - | - | SST_GLO_SST_L4_REP_OBSERVATIONS_010_011 | <a href=\"https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/description\" target=\"_blank\">Description</a>| EO:MO:DAT:SST_GLO_SST_L4_REP_OBSERVATIONS_010_011 | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AMO%3ADAT%3ASST_GLO_SST_L4_REP_OBSERVATIONS_010_011\" target=\"_blank\">Description</a> |\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know how to;\n",
    "* download SLSTR Level-2 SST products from the EUMETSAT Data Store\n",
    "* spatially plot SLSTR data for the Great Barrier Reef (GBR) region\n",
    "* download OSTIA reprocessed SST data from WEkEO using the harmonised data access (HDA) API\n",
    "* make a \"climate stripes\" plot over the GBR region\n",
    "* check for marine heat waves in the GBR region\n",
    "\n",
    "### Outline\n",
    "\n",
    "Concurrent with the past century's persistent warming of global oceans, marine heatwaves (periods of extreme regional ocean warming) have become more frequent and more extreme (Laufkötter et al., 2020). They occur in many areas around the world, from the Pacific Ocean to the Atlantic Ocean to the Mediterranean Sea and threaten marine biodiversity and its ecosystems (Smale et al., 2019). One particular ecosystem impacted by marine heatwaves, are coral reefs. These heatwaves can, for example, cause coral bleaching, coral disease outbreaks, and/or algae blooms (Roberts et al., 2019). Although coral can survive these so-called bleaching events, they become more stressed, more susceptible to diseases, and, on the long-term, subject to mortality (NOAA, 2021).\n",
    "\n",
    "In this notebook we will work through an example of how you can access near-real-time data to view current SST in a region that is often affected by marine heatwaves. We will then look at this area in a long term context using a reprocessed time series, to see how the current situation compares to historical marine heat wave episodes.\n",
    "\n",
    "This Jupyter Notebook builds on the **<a href=\"https://user.eumetsat.int/resources/case-studies/marine-heatwave-intensification-threatens-coral-reef-health\" target=\"_blank\">Marine heatwave intensification threatens coral reef health</a>** case study, and will replicate the figures 3, 5 and 6 using Level-2 data from the Copernicus Sentinel-3 SLSTR sensor and Level-4 data from the Level-4 global OSTIA record. You can find more information on these in the links above.\n",
    "\n",
    "As part of the **<a href=\"https://www.oceandecade.org/\" target=\"_blank\">United Nations Ocean Decade</a>**, ten specific challenges are being addressed. This work, and the data underlying it, support \"Challenge 2 - Protect and restore ecosystems and biodiversity\". Data on marine heatwaves can help characterise the stressors facing marine ecosystems under climate changes, and contribute to decision making to protect, manage and restore those affected.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOCTOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "    \n",
    " 1. [Step 1: Setting up our analysis](#section1)\n",
    " 1. [Step 2: Acquiring SLSTR data via the WEkEO HDA adaptor](#section2)\n",
    " 1. [Step 3: Plotting SLSTR data spatially](#section3)\n",
    " 1. [Step 4: Downloading OSTIA SST data from the Copernicus Marine Service (CMEMS)](#section4)\n",
    " 1. [Step 5: Preparing the OSTIA data](#section5)\n",
    " 1. [Step 6: Making SST-based climate stripes](#section6)\n",
    " 1. [Step 7: Testing for marine heatwaves](#section7)\n",
    " 1. [Step 8 (Optional): Challenge](#section8)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>1. Setting up our analysis\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing all of the libraries that we need to run this notebook. If you have built your python using the environment file provided in this repository, then you should have everything you need. For more information on building environment, please see the repository **<a href=\"../../../README.md\" target=\"_blank\">README</a>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy                        # a library that supports mapping and projection\n",
    "import datetime                       # a library that allows us to work with dates and times\n",
    "import glob                           # a package that helps with file searching\n",
    "import matplotlib.pyplot as plt       # a library the provides plotting capability\n",
    "import numpy as np                    # a library that lets us work with arrays; we import this with a new name \"np\"\n",
    "import os                             # a library that allows us access to basic operating system commands\n",
    "import shutil                         # a library that allows us access to basic operating system commands like copy\n",
    "import xarray as xr                   # a powerful library that helps us work efficiently with multi-dimensional arrays\n",
    "import zipfile                        # a library that allows us to unzip zip-files.\n",
    "import eumartools                     # a library that helps us work with Sentinel-3 data\n",
    "from hda import Client, Configuration # a library to help us access EUMETSAT data on WEkEO\n",
    "import warnings                       # a library the helps us to manage warnings\n",
    "import copernicusmarine               # a library to help us access CMEMS data\n",
    "from pathlib import Path              # a library to help us to construct system paths\n",
    "import getpass                        # a library to help us enter passwords\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following library supports the detection of marine heat waves. More information is available at the following links:\n",
    "\n",
    "- **<a href=\"https://github.com/coecms/xmhw\" target=\"_blank\">The imported package</a>**\n",
    "- **<a href=\"https://github.com/ecjoliver/marineHeatWave\" target=\"_blank\">The original development package by Eric Oliver (not imported here)</a>**\n",
    "- **<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0079661116000057?casa_token=k4Z_r0jQNNkAAAAA:Z1aQSNHpiGFC0OJMYfmCuCGCQ_DOqymmhwz0FWDChKh_nsCrm1WKGNWfsBH7CzwKpWUCfDbPXSw\" target=\"_blank\">The supporting reference (Hobday et al., 2016)</a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmhw.xmhw import detect, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create a directory to download our data to. We will be downloading ~3 Gb worth of Level-2 SLSTR SST products and CMEMS OSTIA reprocessed SST products. We will process some of this \"on the fly\" to reduce local space requirements. The output of this processing will be stored in the `precomputed` directory, which we will also create below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a download and precomputed directory for our SLSTR and CMEMS products\n",
    "download_dir = os.path.join(os.getcwd(), \"products\")\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "precomputed_dir = os.path.join(os.getcwd(), \"precomputed\")\n",
    "os.makedirs(precomputed_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a switch that determines if we should download new data. If `download_data = False` the notebook will look for existing, locally processed data, saving us time if we run more than once. By default this is set to true, assuming that the notebook has not yet been run.\n",
    "\n",
    "We will also define a regions over which to plot our SLSTR SST products and extract our OSTIA SST data. The sub-sampling parameter allows us to reduce the SLSTR grid, which may be necessary if you are running on a memory limited environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should we download new data?\n",
    "download_data = True\n",
    "\n",
    "# plot region for SLSTR data: W, E, S, N\n",
    "plot_region = [142.0, 156.0, -25.0, -10.0]\n",
    "\n",
    "# sub-sampling for SLSTR pre-processing: default = 1 implies no subsampling \n",
    "plot_data_subsample = 1\n",
    "\n",
    "# OSTIA MHW region W, S, E, N\n",
    "CMEMS_dataset_id = \"METOFFICE-GLO-SST-L4-REP-OBS-SST\"\n",
    "CMEMS_dataset_variables = [\"analysed_sst\"]\n",
    "MHW_region = [147.0, -18.0, 148.0, -17.0]\n",
    "start_year, end_year = [1992, 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "\n",
    "## <a id='sectionSF'></a>Supporting functions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, we will define a short function. This manages the pre-processing of our SLSTR data, extracting only the variables we need (`sea_surface_temperature`, `sses_bias`, `quality_level`) and only over the region we defined above, and applying our subsampling as required. Later, we will call this function as part of our download process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SST_granule(SST_file, region, subsample=1, quality_level=4):\n",
    "    \"\"\"\n",
    "    Quick function to process Level-2 SLSTR granules for memory management. \n",
    "    Regionally subsets, applies bias and masks out values lower than the quality level.\n",
    "\n",
    "    Args:\n",
    "        SST_file (string)        : the file to process\n",
    "        region (list)            : the area subset to use when extracting data\n",
    "        subsample (int)          : the grid subsampling parameter\n",
    "        quality_level (int)      : the quality level to flag SLSTR data at. Anything lower than this value \n",
    "                                   will be discarded\n",
    "    Returns:\n",
    "        lon (array)              : the extracted longitude\n",
    "        lat (array)              : the extracted latitude\n",
    "        bias_corr_QC_SST (array) : the extracted, bias corrected, quality flagged SST\n",
    "\n",
    "    \"\"\"\n",
    "    K_to_C = 273.15\n",
    "    \n",
    "    SST_data = xr.open_dataset(SST_file)\n",
    "\n",
    "    ext_x, ext_y, ext_mask = eumartools.subset_image(SST_data[\"lon\"][::subsample,::subsample],\n",
    "                                                     SST_data[\"lat\"][::subsample,::subsample], \n",
    "                                                     [region[0], region[1], region[1], region[0]],\n",
    "                                                     [region[2], region[2], region[3], region[3]],\n",
    "                                                     mode='global')\n",
    "    \n",
    "    ext_x = [i * subsample for i in ext_x] ; ext_y = [i * subsample for i in ext_y]\n",
    "    minx = np.nanmin(ext_x) ; maxx = np.nanmax(ext_x) ; miny = np.nanmin(ext_y) ; maxy = np.nanmax(ext_y) \n",
    "\n",
    "    bias_corr_QC_SST = np.squeeze(\n",
    "                       np.array(SST_data[\"sea_surface_temperature\"][0,miny:maxy:subsample,minx:maxx:subsample]\n",
    "                              + SST_data[\"sses_bias\"][0,miny:maxy:subsample,minx:maxx:subsample] - K_to_C))\n",
    "\n",
    "    flags = np.squeeze(np.array(SST_data[\"quality_level\"][0,miny:maxy:subsample,minx:maxx:subsample]))\n",
    "    bias_corr_QC_SST[flags < 4] = np.nan\n",
    "\n",
    "    lon = np.squeeze(np.array(SST_data[\"lon\"][miny:maxy:subsample,minx:maxx:subsample]))\n",
    "    lat = np.squeeze(np.array(SST_data[\"lat\"][miny:maxy:subsample,minx:maxx:subsample]))\n",
    "    SST_data.close()\n",
    "\n",
    "    return lon, lat, bias_corr_QC_SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>2. Acquiring SLSTR data via the WEkEO HDA adaptor\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing the WEkEO Catalog\n",
    "\n",
    "To access Copernicus marine data from the WEkEO catalogue, we can use the <a href=\"https://help.wekeo.eu/en/articles/6751608-what-is-the-hda-api-python-client-and-how-to-use-it\" target=\"_blank\">Harmonised Data Access (HDA) API</a>. If you are currently working on the WEkEO JupyterHub, the Python package that suports the HDA will already be installed. Otherwise, if you are working with the recommended Anaconda Python distribution and used the environment file supplied with this repository (environment.yml) to build this python environment (as detailed in the README), you will already have installed this. If not, you can install `hda` using;\n",
    "\n",
    "`conda install -c conda-forge hda`\n",
    "\n",
    "You can also find the source code on the <a href=\"https://github.com/ecmwf/hda\" target=\"_blank\">HDA GitHub</a>.\n",
    "\n",
    "To download data using the WEkEO HDA API, you need to provide credentials. To obtain these, you should register at <a href=\"https://www.wekeo.eu/\" target=\"_blank\">https://www.wekeo.eu/</a> for an account and take note of you `username` and `password`. If you do not already have a local credentials file, you will be prompted to enter your credentials when you run the cell below. This will create the required local credentials file, so that you only need to run this once.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default location expected by hda package\n",
    "wekeo_credentials_file = Path(Path.home() / '.hdarc')\n",
    "\n",
    "# Create it only if it does not already exists\n",
    "if not wekeo_credentials_file.is_file():\n",
    "    USERNAME = input('Enter your username: ')\n",
    "    PASSWORD = getpass.getpass('Enter your password: ')\n",
    "\n",
    "    with open(wekeo_credentials_file, 'w') as f:\n",
    "        f.write(f'user:{USERNAME}\\n')\n",
    "        f.write(f'password:{PASSWORD}\\n')\n",
    "\n",
    "hda_client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WEkEO HDA client accepts requests as JSON queries. These have a specific format, which may look complex, but you can build on the examples you can find in the GUI, available under the **Show API request** button;\n",
    "\n",
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/raw/main/img/WEkEO_show_api_SLSTR.png' align='centre' width='75%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEkEO collections are stored according to a `datasetId`, which for SLSTR Level-2 products is `EO:EUM:DAT:SENTINEL-3:SL_2_WST___` (as specified in the *Data Used* section above). WEkEO allows you to search for data in time and space. Lets constrain our product selection using the bounding box defined above, and our start and end times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "\"dataset_id\": \"EO:EUM:DAT:SENTINEL-3:SL_2_WST___\",\n",
    "\"bbox\": [plot_region[0], plot_region[2], plot_region[1], plot_region[3]],\n",
    "\"dtstart\": \"2021-12-22T12:37:36.000Z\",\n",
    "\"dtend\": \"2021-12-22T12:37:37.000Z\",\n",
    "\"type\": \"SL_2_WST___\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section of code prints the names of the files that have been found during the search..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_data:\n",
    "    matches = hda_client.search(query)\n",
    "    for match in matches.results:\n",
    "        fdst = match['id']\n",
    "        print(f\"Found: {fdst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will download our products one-by-one. Once we have downloaded a product, we will unzip it and also subset the file and strip out any variables we don't need to save local storage space. This will be stored in the `precomputed` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_data:\n",
    "    for match in matches:\n",
    "\n",
    "        # Download the product\n",
    "        product = match.results[0]['id']\n",
    "        fname = '\"' + product + '.zip\"' ## WEkEO bug fix\n",
    "        \n",
    "        print(f\"Downloading and processing: {product}\")\n",
    "        match.download()\n",
    "\n",
    "        # Unzip the product\n",
    "        with zipfile.ZipFile(fname, 'r') as zip_ref: ## WEkEO bug fix\n",
    "            zip_ref.extractall(download_dir)\n",
    "            print(f'Unzipping of product {product} finished.')\n",
    "            os.remove(fname) ## WEkEO bug fix\n",
    "\n",
    "        # process downloaded file\n",
    "        SST_file = glob.glob(os.path.join(download_dir, product, \"*.nc\"))[0]\n",
    "        OUT_file = os.path.join(precomputed_dir, product.replace('.SEN3','_subset.nc'))\n",
    "        lon, lat, sst = process_SST_granule(SST_file, plot_region, subsample=plot_data_subsample)\n",
    "        \n",
    "        # write to new netCDF file\n",
    "        ds = xr.Dataset({\"sst\": ((\"x\", \"y\"), sst)},\n",
    "                        coords={\"lat\": ((\"x\", \"y\"), lat), \n",
    "                                \"lon\": ((\"x\", \"y\"), lon)})\n",
    "        ds.to_netcdf(OUT_file, format='NETCDF4_CLASSIC')\n",
    "\n",
    "        # remove full size download\n",
    "        shutil.rmtree(os.path.join(download_dir, product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section3'></a>3. Plotting SLSTR data spatially\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by collecting our download Level-2 SLSTR SST products..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the files\n",
    "SLSTR_files = glob.glob(os.path.join(precomputed_dir, '*.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate through the images and plot them. The box below will set up our plot and do this for us. This will be the same as figure 3 on the case study. This code cell looks complex, but most of it is related to setting up our figure and embellishing our plot. Each section has a short comment describing what is done.\n",
    "\n",
    "*Note:  Note that this routine does not perform any binning, so newer data is just overlaid. The result is NOT a Level-3 product, but a level 2 mosaic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup figure\n",
    "fig, m = plt.subplots(1, 1, figsize=(10, 14), dpi=300, subplot_kw={\"projection\": cartopy.crs.PlateCarree()})\n",
    "\n",
    "# setup plot 1: the composite\n",
    "m.set_extent(plot_region)\n",
    "\n",
    "# make the plot: we will call this as a function as it contains a 'for' loop to iterate over our SLSTR granules.\n",
    "for SLSTR_file in SLSTR_files:\n",
    "    # plot the SST field\n",
    "    SST_data = xr.open_dataset(SLSTR_file)\n",
    "    p1 = m.pcolormesh(SST_data[\"lon\"], SST_data[\"lat\"],\n",
    "                      SST_data[\"sst\"], cmap=plt.cm.RdYlBu_r,\\\n",
    "                      vmin=27, vmax=30, zorder=1)\n",
    "    SST_data.close()\n",
    "\n",
    "# add some map embellishments\n",
    "m.add_feature(cartopy.feature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='k', facecolor='#546d51', linewidth=0.5))\n",
    "g1 = m.gridlines(draw_labels = True, linestyle='--', linewidth=0.5, zorder=1000)\n",
    "g1.top_labels = g1.right_labels = False\n",
    "g1.xlabel_style = g1.ylabel_style = {'color': '0.5'}\n",
    "\n",
    "# add a colour bar\n",
    "cbar = fig.colorbar(p1, ax=m, location='bottom', pad=0.05)\n",
    "cbar.ax.tick_params() \n",
    "cbar.set_label('SLSTR night-time SST composite, 22 Dec 2021 [$^{o}$C]')\n",
    "plt.savefig('SLSTR_composite_22122021.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section4'></a>4. Downloading OSTIA SST data from the Copernicus Marine Service (CMEMS)\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To place the image above in context we'll need to look at a time series of data. For this we can access data from the Copernicus Marine Service, where multiple data sources (different satellites etc) are combined to produce data sets that cover longer time periods. In this case we are going to look at the <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AMO%3ADAT%3ASST_GLO_SST_L4_REP_OBSERVATIONS_010_011\">OSTIA sea surface temperature</a> reprocessed data stream.\n",
    "\n",
    "If you wish to adapt this to a more recent event you can combine the reprocessed data stream with the NRT data stream. However, reprocessed and NRT data streams are produced separately and we must be careful when we interpret these data sets together. As time progresses, we understand better how satellite instruments perform, algorithms improve, and data is reprocessed to ensure good quality and consistency between sources. With NRT we do not have all the information we have in hindsight, particularly about instrument characterisation, but this data is vitally important for understanding events that are happening right now. So, for example, you would not use combined NRT and reprocessed data sets for long-term trend analysis, and you would want to consider NRT measurements with a higher degree of uncertainty that you might consider with reprocessed data. So whilst we can use the NRT data now to get an indication of whether this is event is looking like it might be significant, we would eventually want to use a longer term time series that have been reprocessed, to establish how unusual this is event is in a more climatic context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing Copernicus Marine Service products\n",
    "\n",
    "To retrieve the data, we need will use the <a href=\"https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction\" target=\"_blank\">Copernicus Marine API</a>. This allows us to remotely subset the data and read it directly into memory, for immediate use. If you are working with the recommended Anaconda Python distribution and used the environment file included in this repository (environment.yml) to build this python environment (as detailed in the README), you will already have installed this. If not, you can install the toolkit using;\n",
    "\n",
    "`conda install -c conda-forge copernicusmarine`\n",
    "\n",
    "To download data using the Copernicus Marine API, you need to provide credentials. To obtain these, you should register at the <a href=\"https://data.marine.copernicus.eu/register\" target=\"_blank\">Copernicus Marine Service</a> for an account and take note of you `username` and `password`. If you do not already have a local credentials file, you will be prompted to enter your credentials when you run the cell below. This will create the required local credentials file, so that you only need to run this once.\n",
    "\n",
    "*Note: For more information on authentication options please see this <a href=\"https://help.marine.copernicus.eu/en/articles/8185007-copernicus-marine-toolbox-credentials-configuration\" target=\"_blank\">web article</a>.*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default location expected by the copernicusmarine package\n",
    "copernicus_marine_credentials_file = Path(Path.home() / '.copernicusmarine' / '.copernicusmarine-credentials')\n",
    "\n",
    "# Create it only if it does not already exists\n",
    "if not copernicus_marine_credentials_file.is_file():\n",
    "    copernicusmarine.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets request our data cube based on the parameters we described above and make it available immediately as an xarray object in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_data = copernicusmarine.open_dataset(\n",
    "           dataset_id = CMEMS_dataset_id,\n",
    "           variables=CMEMS_dataset_variables,\n",
    "           minimum_longitude=MHW_region[0],\n",
    "           maximum_longitude=MHW_region[2],\n",
    "           minimum_latitude=MHW_region[1],\n",
    "           maximum_latitude=MHW_region[3],\n",
    "           start_datetime=\"{start_year}-01-01T00:00:00.000Z\".format(start_year = start_year),\n",
    "           end_datetime=\"{end_year}-12-31T00:00:00.000Z\".format(end_year = end_year)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section5'></a>5. Preparing the OSTIA data\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a bit or preprocessing on the OSTIA data to make it easier to use for our purposes. We begin by calculating spatial averages, annual values, and then, from these an SST anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_spatial_average = SST_data.mean(dim='latitude').mean(dim='longitude')\n",
    "SST_annual_values = SST_spatial_average.groupby('time.year').mean('time')\n",
    "SST_anomaly = SST_annual_values[\"analysed_sst\"] - SST_annual_values[\"analysed_sst\"].mean(dim=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section6'></a>6. Making SST-based climate stripes\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plot we'll make, shows ‘stripes’ of the average sea surface temperature anomaly for our region of interest. Recently, ‘climate stripes’ have been used by 'citizen scientists' all over the world to show long-term trends in regional temperatures. First we need to do a bit of formatting to get our array in the right size for the plot we want to make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are dropping the final year, in case it is not complete!\n",
    "SST_stripes = np.squeeze(np.array(SST_anomaly[:-1]))\n",
    "SST_stripes_2D = np.repeat(SST_stripes[np.newaxis,...], 2, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot our stripes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10), dpi=300)\n",
    "\n",
    "vmax = np.nanmax(abs(SST_stripes))\n",
    "\n",
    "plt.pcolormesh(SST_stripes_2D, vmin=vmax*-1, vmax=vmax, cmap=plt.cm.RdBu_r)\n",
    "plt.xticks(np.arange(len(SST_anomaly))+0.5, SST_anomaly.year.values, rotation=90)\n",
    "plt.xlim([0,len(SST_anomaly)-1])\n",
    "plt.yticks([],[])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('SST anomaly [$^{o}$C]')\n",
    "plt.savefig('Climate_stripes_GBR.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows a stripes-style graphic derived using the SST time series we have extracted. High anomalies are apparent during the 1998 (strong El Niño), 2010, 2016 (strong El Niño), 2017, 2020 and 2021. There are also strong suggestions of a warming over time, with four of the six warmest years recorded after 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section7'></a>7. Testing for marine heatwaves\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to do a little bit of analysis to see if we can routinely identify heatwaves in our time series. We can do this using an open toolkit developed for this purpose by Hobday et al., (you can see it imported at the top of this notebook in an xarray based implementation). \n",
    "\n",
    "Initially, we need to do some formatting to get the dates for our time series in the right format for ingestion in to the toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [datetime.datetime.strptime(str(i), \"%Y-%m-%dT%H:%M:%S.%f000\").toordinal() \n",
    "           for i in np.asarray(SST_spatial_average[\"time\"])]\n",
    "\n",
    "doy = [datetime.datetime.strptime(str(i), \"%Y-%m-%dT%H:%M:%S.%f000\").timetuple().tm_yday - 1\n",
    "       for i in SST_spatial_average[\"time\"].values]\n",
    "\n",
    "dates = [datetime.datetime.fromordinal(tt) for tt in times]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the analysis, which first establishes a threshold based on the time series and then detects instances where this is exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_time_series = SST_spatial_average[\"analysed_sst\"] - 273.15\n",
    "clim = threshold(SST_time_series)\n",
    "mhws = detect(SST_time_series, clim['thresh'], clim['seas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get the toolkit to tell us how many events are present in our time series..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = len(mhws['event'])\n",
    "print(f\"Number of heatwaves: {n_events}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also plot the time series, and show where the events identified occurred..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10), dpi=300)\n",
    "\n",
    "p1, = plt.plot(SST_spatial_average[\"time\"], clim['seas'].values[doy], 'b--', linewidth=1, zorder=1)\n",
    "p2, = plt.plot(SST_spatial_average[\"time\"], clim['thresh'].values[doy], 'r', linewidth=1, zorder=2)\n",
    "p3, = plt.plot(SST_spatial_average[\"time\"], SST_time_series, 'k', linewidth=1, zorder=3)\n",
    "\n",
    "# Find indices for previous MHW and shade\n",
    "for ev0 in np.arange(n_events):\n",
    "    t1 = np.where(SST_spatial_average[\"time\"]==mhws['time_start'][ev0].values)[0][0]\n",
    "    t2 = np.where(SST_spatial_average[\"time\"]==mhws['time_end'][ev0].values)[0][0]\n",
    "    if ev0 == n_events - 1:\n",
    "        plot_col = 'r'\n",
    "    else:\n",
    "        plot_col = (1,0.6,0.5)\n",
    "    plt.fill_between(np.array(dates[t1:t2+1]), clim['thresh'].values[doy][t1:t2+1], np.array(SST_time_series[t1:t2+1]), \\\n",
    "                     color=plot_col)\n",
    "\n",
    "plt.xlim(SST_spatial_average[\"time\"][-1000], SST_spatial_average[\"time\"][-1])\n",
    "plt.ylim(clim['seas'].min() - 1, clim['seas'].max() + 2)\n",
    "plt.ylabel(r'SST [$^\\circ$C]')\n",
    "plt.legend([p1, p2, p3],[\"Seasonal climatology\", \"Threshold\", \"SST\"], frameon=False)\n",
    "plt.savefig('Marine_heat_waves_GBR.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an example of the sorts of analyses that can be developed with SST data for marine heatwaves. The diversity of data available through Copernicus programme allows for the investigation of this phenomena at both the event and climate scales. To extend this analysis you could use a longer time series of data to determine climate related trends. You could also routinely compare NRT data to a climatology (with the caveat of greater uncertainty associated with the NRT data source) for any region of interest to investigate it's current MHW status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "\n",
    "## <a id='section8'></a>8. Challenge\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example we have checked for heatwaves over the Great Barrier Reef, using a data set that spans 1992 to mid-2022. If you want to try another experiment you can easily adapt the following settings in [section 1](#section1) to do so:\n",
    "\n",
    "```\n",
    "# OSTIA MHW region W, S, E, N\n",
    "CMEMS_dataset_id = \"METOFFICE-GLO-SST-L4-REP-OBS-SST\" (perhaps try \n",
    "CMEMS_dataset_variables = [\"analysed_sst\"]\n",
    "MHW_region = [147.0, -18.0, 148.0, -17.0]\n",
    "start_year, end_year = [1992, 2022]\n",
    "```\n",
    "\n",
    "We recommend you set `download_data = False` if you plan to re-run this, to avoid downloading new SLSTR level-2 products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a href=\"../../../../Index.ipynb\"><< Index</a>\n",
    "<hr>\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int>Contact helpdesk for support </a> | <a href=mailto:training@eumetsat.int>Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "author": "Ben Loveday, Hayley Evers-King",
  "description": "This UN Ocean Decade challenge Jupyter Notebook, shows how to investigate marine heatwaves using EUMETSAT Sentinel-3 SLSTR and CMEMS OSTIA SST products.",
  "image": "../../../../img/thumbs/Marine_heatwaves_intensification_threatens_coral_reef_health_thumb.png",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "services": {
   "eumetsat": {
    "binder": {
     "link": "https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2ocean-case-studies/HEAD?urlpath=%2Ftree%2FCase_studies%2FUN_Ocean_Decade%2FChallenge02_ecosystems_and_biodiversity%2FMarine_heat_wave_intensification_threatens_coral_reef_health%2FMarine_heat_wave_intensification_threatens_coral_reef_health.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "git": {
     "link": "https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/blob/main/Case_studies/UN_Ocean_Decade/Challenge02_ecosystems_and_biodiversity/Marine_heat_wave_intensification_threatens_coral_reef_health/Marine_heat_wave_intensification_threatens_coral_reef_health.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   },
   "wekeo": {
    "git": {
     "link": "https://github.com/wekeo/ocean-case-studies/blob/main/Case_studies/UN_Ocean_Decade/Challenge02_ecosystems_and_biodiversity/Marine_heat_wave_intensification_threatens_coral_reef_health/Marine_heat_wave_intensification_threatens_coral_reef_health.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "url": {
     "link": "https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/UN_Ocean_Decade/Challenge02_ecosystems_and_biodiversity/Marine_heat_wave_intensification_threatens_coral_reef_health/Marine_heat_wave_intensification_threatens_coral_reef_health.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   }
  },
  "tags": {
   "domain": [
    "Marine",
    "Climate"
   ],
   "platform": [
    "Sentinel-3",
    "CMEMS"
   ],
   "sensor": [
    "SLSTR",
    "OSTIA"
   ],
   "service": [
    "EUMETSAT",
    "CMEMS"
   ],
   "subtheme": "Climate system monitoring - Ocean",
   "tags": "Sea surface temperature"
  },
  "title": "Exploring marine heatwaves with Sentinel-3 SLSTR and CMEMS OSTIA SST"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
